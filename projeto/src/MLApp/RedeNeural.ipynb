{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Unnamed: 0  Strike  Maturity  Spot  TaxaDesconto  Premio  CallPut  \\\n",
      "0                 0    10.0       0.2   8.5          0.08    1.00        0   \n",
      "2                 2    10.0       0.2   8.5          0.08    1.25        0   \n",
      "4                 4    10.0       0.2   8.5          0.08    1.50        0   \n",
      "5                 5    10.0       0.2   8.5          0.08    1.50        1   \n",
      "6                 6    10.0       0.2   8.5          0.08    1.75        0   \n",
      "...             ...     ...       ...   ...           ...     ...      ...   \n",
      "2303995     2303995    14.9       0.9  17.2          0.10    4.25        1   \n",
      "2303996     2303996    14.9       0.9  17.2          0.10    4.50        0   \n",
      "2303997     2303997    14.9       0.9  17.2          0.10    4.50        1   \n",
      "2303998     2303998    14.9       0.9  17.2          0.10    4.75        0   \n",
      "2303999     2303999    14.9       0.9  17.2          0.10    4.75        1   \n",
      "\n",
      "           Result  \n",
      "0        0.976155  \n",
      "2        1.141012  \n",
      "4        1.305903  \n",
      "5        0.372832  \n",
      "6        1.471229  \n",
      "...           ...  \n",
      "2303995  1.052958  \n",
      "2303996  0.393964  \n",
      "2303997  1.103450  \n",
      "2303998  0.446271  \n",
      "2303999  1.154466  \n",
      "\n",
      "[1341925 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_19520\\2829134534.py:47: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataframes['CallPut'] = dataframes['CallPut'].replace({'call': 0, 'put': 1})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dataframes = pd.DataFrame()\n",
    "\n",
    "# base1 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_4a10_spot_3.5a12.2\\\\base_de_dados_1.csv\")\n",
    "# results1 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_4a10_spot_3.5a12.2\\\\result_1.csv\")\n",
    "        \n",
    "# df_result_filtrado = results1[results1['0'].notna()]\n",
    "# indices_to_keep = df_result_filtrado.index\n",
    "# df_inputs_filtrado = base1.loc[indices_to_keep]\n",
    "# df_filtrado = pd.concat([df_inputs_filtrado, df_result_filtrado], axis=1)\n",
    "# dataframes = pd.concat([dataframes, df_filtrado], axis = 0)\n",
    "\n",
    "base2 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_10a15_spot_8.5a17.2\\\\base_de_dados_2.csv\")\n",
    "results2 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_10a15_spot_8.5a17.2\\\\result_2.csv\")\n",
    "        \n",
    "df_result_filtrado = results2[(results2['Result'].notna()) & (results2['Result'] != -1)]\n",
    "indices_to_keep = df_result_filtrado.index\n",
    "df_inputs_filtrado = base2.loc[indices_to_keep]\n",
    "df_inputs_filtrado['Result'] = df_result_filtrado['Result']\n",
    "# df_filtrado = pd.concat([dataframes, df_result_filtrado], axis=1)\n",
    "\n",
    "dataframes = pd.concat([dataframes, df_inputs_filtrado], axis = 0)\n",
    "\n",
    "# base3 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_15a20_spot_12.5a22.5\\\\base_de_dados_3.csv\")\n",
    "# results3 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_15a20_spot_12.5a22.5\\\\result_3.csv\")\n",
    "        \n",
    "# df_result_filtrado = results3[(results3['Result'].notna()) & (results3['Result'] != -1)]\n",
    "# df_result_filtrado_sem_invalidos = results3[results3['0'].notna()]\n",
    "# indices_to_keep = df_result_filtrado.index\n",
    "# df_inputs_filtrado = base3.loc[indices_to_keep]\n",
    "# df_inputs_filtrado['Result'] = df_result_filtrado['Result']\n",
    "# dataframes = pd.concat([dataframes, df_inputs_filtrado], axis = 0)\n",
    "\n",
    "# print(dataframes.head())\n",
    "\n",
    "# base4 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_20a25_spot_17.5a27.5\\\\base_de_dados_4.csv\")\n",
    "# results4 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_20a25_spot_17.5a27.5\\\\result_4.csv\")\n",
    "        \n",
    "# df_result_filtrado = results4[results4['0'].notna()]\n",
    "# indices_to_keep = df_result_filtrado.index\n",
    "# df_inputs_filtrado = base4.loc[indices_to_keep]\n",
    "# df_filtrado = pd.concat([df_inputs_filtrado, df_result_filtrado], axis=1)\n",
    "# dataframes = pd.concat([dataframes, df_filtrado], axis = 0)\n",
    "\n",
    "dataframes['CallPut'] = dataframes['CallPut'].replace({'call': 0, 'put': 1})\n",
    "print(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1341925\n",
      "805145\n",
      "256525\n",
      "127055\n",
      "112619\n"
     ]
    }
   ],
   "source": [
    "print(dataframes.shape[0])\n",
    "df_filtrado = dataframes[dataframes['TaxaDesconto'].isin([0.08, 0.09, 0.1])]\n",
    "print(df_filtrado.shape[0])\n",
    "df_filtrado = df_filtrado[df_filtrado['Maturity'].isin([0.2, 0.3, 0.4])]\n",
    "print(df_filtrado.shape[0])\n",
    "df_filtrado = df_filtrado[df_filtrado['CallPut'].isin([0])]\n",
    "print(df_filtrado.shape[0])\n",
    "\n",
    "df_filtrado = df_filtrado[(df_filtrado['Spot'] >= 9.5) & (df_filtrado['Spot'] <= 15.5)]\n",
    "print(df_filtrado.shape[0])\n",
    "\n",
    "dataframes = df_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separando as features e o alvo\n",
    "X = dataframes[['Strike', 'Maturity', 'Spot', 'TaxaDesconto','Premio','CallPut']].values\n",
    "y = dataframes['Result'].values\n",
    "\n",
    "# Dividindo os dados em conjunto de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizando os dados\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.06909289 0.67935139 0.86786096 ... 0.33472198 0.7823687  2.20447742]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6983673\n",
      "object\n",
      "1745919\n",
      "object\n",
      "6983673\n",
      "int64\n",
      "1745919\n",
      "int64\n",
      "###########################\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'call'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 21\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m###########################\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# print(np.isnan(X_train).any())  # Deve retornar False\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# print(np.isinf(X_train).any())  # Deve retornar False\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# print(np.isnan(y_test).any())  # Deve retornar False\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# print(np.isinf(y_test).any())  # Deve retornar False\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_test, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     23\u001b[0m y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_train, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'call'"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(X_train.dtype)\n",
    "print(len(X_test))\n",
    "print(X_test.dtype)\n",
    "print(len(y_train))\n",
    "print(y_train.dtype)\n",
    "print(len(y_test))\n",
    "print(y_test.dtype)\n",
    "print(\"###########################\")\n",
    "\n",
    "# print(np.isnan(X_train).any())  # Deve retornar False\n",
    "# print(np.isinf(X_train).any())  # Deve retornar False\n",
    "\n",
    "# print(np.isnan(X_test).any())  # Deve retornar False\n",
    "# print(np.isinf(X_test).any())  # Deve retornar False\n",
    "# print(np.isnan(y_train).any())  # Deve retornar False\n",
    "# print(np.isinf(y_train).any())  # Deve retornar False\n",
    "# print(np.isnan(y_test).any())  # Deve retornar False\n",
    "# print(np.isinf(y_test).any())  # Deve retornar False\n",
    "\n",
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "y_test = np.array(y_test, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Definindo a arquitetura da rede neural\n",
    "model = Sequential()\n",
    "\n",
    "# Camada de entrada com 4 neurônios (correspondendo aos 4 inputs)\n",
    "model.add(Dense(30, input_dim=6, activation='relu'))\n",
    "\n",
    "# Camada oculta com 32 neurônios\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Camada oculta com 16 neurônios\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "\n",
    "# Camada de saída com 1 neurônio (correspondendo à volatilidade implícita)\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mY_train\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26839/26839\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 4ms/step - loss: 0.0505 - val_loss: 0.0011\n"
     ]
    }
   ],
   "source": [
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
    "\n",
    "# Ajustando o modelo com os dados normalizados\n",
    "history = model.fit(X_train_scaled, y_train_scaled, epochs=1, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8388/8388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - loss: 0.0011\n",
      "Loss no conjunto de teste: 0.0010939588537439704\n",
      "\u001b[1m8388/8388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Normalizando X_test\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "# Normalizando y_test para a avaliação\n",
    "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Avaliando o desempenho do modelo no conjunto de teste\n",
    "loss = model.evaluate(X_test_scaled, y_test_scaled)\n",
    "print(f'Loss no conjunto de teste: {loss}')\n",
    "\n",
    "# Fazendo previsões\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Desnormalizando as previsões\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
      "[[-0.37951028]\n",
      " [-0.7070981 ]\n",
      " [-0.40410817]]\n",
      "[0.75122208 1.03344043 0.71570995]\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "\n",
    "y_pred = model.predict(X_new)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "print(y_test[:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
