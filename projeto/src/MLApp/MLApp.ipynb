{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Unnamed: 0  Strike  Maturity  Spot  TaxaDesconto  Premio  CallPut  \\\n",
      "0                 0    10.0       0.2   8.5          0.08    1.00        0   \n",
      "2                 2    10.0       0.2   8.5          0.08    1.25        0   \n",
      "4                 4    10.0       0.2   8.5          0.08    1.50        0   \n",
      "5                 5    10.0       0.2   8.5          0.08    1.50        1   \n",
      "6                 6    10.0       0.2   8.5          0.08    1.75        0   \n",
      "...             ...     ...       ...   ...           ...     ...      ...   \n",
      "3199995     3199995    19.9       0.9  22.2          0.10    5.25        1   \n",
      "3199996     3199996    19.9       0.9  22.2          0.10    5.50        0   \n",
      "3199997     3199997    19.9       0.9  22.2          0.10    5.50        1   \n",
      "3199998     3199998    19.9       0.9  22.2          0.10    5.75        0   \n",
      "3199999     3199999    19.9       0.9  22.2          0.10    5.75        1   \n",
      "\n",
      "           Result  \n",
      "0        0.976155  \n",
      "2        1.141012  \n",
      "4        1.305903  \n",
      "5        0.372832  \n",
      "6        1.471229  \n",
      "...           ...  \n",
      "3199995  0.961180  \n",
      "3199996  0.407871  \n",
      "3199997  0.998644  \n",
      "3199998  0.445758  \n",
      "3199999  1.036357  \n",
      "\n",
      "[3536692 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_19512\\2378283508.py:47: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataframes['CallPut'] = dataframes['CallPut'].replace({'call': 0, 'put': 1})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dataframes = pd.DataFrame()\n",
    "\n",
    "# base1 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_4a10_spot_3.5a12.2\\\\base_de_dados_1.csv\")\n",
    "# results1 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_4a10_spot_3.5a12.2\\\\result_1.csv\")\n",
    "        \n",
    "# df_result_filtrado = results1[results1['0'].notna()]\n",
    "# indices_to_keep = df_result_filtrado.index\n",
    "# df_inputs_filtrado = base1.loc[indices_to_keep]\n",
    "# df_filtrado = pd.concat([df_inputs_filtrado, df_result_filtrado], axis=1)\n",
    "# dataframes = pd.concat([dataframes, df_filtrado], axis = 0)\n",
    "\n",
    "base2 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_10a15_spot_8.5a17.2\\\\base_de_dados_2.csv\")\n",
    "results2 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_10a15_spot_8.5a17.2\\\\result_2.csv\")\n",
    "        \n",
    "df_result_filtrado = results2[(results2['Result'].notna()) & (results2['Result'] != -1)]\n",
    "indices_to_keep = df_result_filtrado.index\n",
    "df_inputs_filtrado = base2.loc[indices_to_keep]\n",
    "df_inputs_filtrado['Result'] = df_result_filtrado['Result']\n",
    "# df_filtrado = pd.concat([dataframes, df_result_filtrado], axis=1)\n",
    "\n",
    "dataframes = pd.concat([dataframes, df_inputs_filtrado], axis = 0)\n",
    "\n",
    "base3 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_15a20_spot_12.5a22.5\\\\base_de_dados_3.csv\")\n",
    "results3 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_15a20_spot_12.5a22.5\\\\result_3.csv\")\n",
    "        \n",
    "df_result_filtrado = results3[(results3['Result'].notna()) & (results3['Result'] != -1)]\n",
    "df_result_filtrado_sem_invalidos = results3[results3['0'].notna()]\n",
    "indices_to_keep = df_result_filtrado.index\n",
    "df_inputs_filtrado = base3.loc[indices_to_keep]\n",
    "df_inputs_filtrado['Result'] = df_result_filtrado['Result']\n",
    "dataframes = pd.concat([dataframes, df_inputs_filtrado], axis = 0)\n",
    "\n",
    "# print(dataframes.head())\n",
    "\n",
    "# base4 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_20a25_spot_17.5a27.5\\\\base_de_dados_4.csv\")\n",
    "# results4 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_20a25_spot_17.5a27.5\\\\result_4.csv\")\n",
    "        \n",
    "# df_result_filtrado = results4[results4['0'].notna()]\n",
    "# indices_to_keep = df_result_filtrado.index\n",
    "# df_inputs_filtrado = base4.loc[indices_to_keep]\n",
    "# df_filtrado = pd.concat([df_inputs_filtrado, df_result_filtrado], axis=1)\n",
    "# dataframes = pd.concat([dataframes, df_filtrado], axis = 0)\n",
    "\n",
    "dataframes['CallPut'] = dataframes['CallPut'].replace({'call': 0, 'put': 1})\n",
    "print(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0      False\n",
      "Strike          False\n",
      "Maturity        False\n",
      "Spot            False\n",
      "TaxaDesconto    False\n",
      "Premio          False\n",
      "CallPut         False\n",
      "Result          False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.isnan(dataframes).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separando as features e o alvo\n",
    "X = dataframes[['Strike', 'Maturity', 'Spot', 'TaxaDesconto','Premio','CallPut']].values\n",
    "y = dataframes['Result'].values\n",
    "\n",
    "# Dividindo os dados em conjunto de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizando os dados\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.85377835  0.67646786 -1.         ... -1.                 nan\n",
      "  0.67303801]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6983673\n",
      "object\n",
      "1745919\n",
      "object\n",
      "6983673\n",
      "int64\n",
      "1745919\n",
      "int64\n",
      "###########################\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'call'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 21\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m###########################\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# print(np.isnan(X_train).any())  # Deve retornar False\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# print(np.isinf(X_train).any())  # Deve retornar False\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# print(np.isnan(y_test).any())  # Deve retornar False\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# print(np.isinf(y_test).any())  # Deve retornar False\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_test, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     23\u001b[0m y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_train, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'call'"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(X_train.dtype)\n",
    "print(len(X_test))\n",
    "print(X_test.dtype)\n",
    "print(len(y_train))\n",
    "print(y_train.dtype)\n",
    "print(len(y_test))\n",
    "print(y_test.dtype)\n",
    "print(\"###########################\")\n",
    "\n",
    "# print(np.isnan(X_train).any())  # Deve retornar False\n",
    "# print(np.isinf(X_train).any())  # Deve retornar False\n",
    "\n",
    "# print(np.isnan(X_test).any())  # Deve retornar False\n",
    "# print(np.isinf(X_test).any())  # Deve retornar False\n",
    "# print(np.isnan(y_train).any())  # Deve retornar False\n",
    "# print(np.isinf(y_train).any())  # Deve retornar False\n",
    "# print(np.isnan(y_test).any())  # Deve retornar False\n",
    "# print(np.isinf(y_test).any())  # Deve retornar False\n",
    "\n",
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "y_test = np.array(y_test, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Definindo a arquitetura da rede neural\n",
    "model = Sequential()\n",
    "\n",
    "# Camada de entrada com 4 neurônios (correspondendo aos 4 inputs)\n",
    "model.add(Dense(64, input_dim=6, activation='relu'))\n",
    "\n",
    "# Camada oculta com 32 neurônios\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Camada oculta com 16 neurônios\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "# Camada de saída com 1 neurônio (correspondendo à volatilidade implícita)\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mY_train\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take the length of shape with unknown rank.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m y_train_scaled \u001b[38;5;241m=\u001b[39m scaler_y\u001b[38;5;241m.\u001b[39mfit_transform(y_train\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Ajustando o modelo com os dados normalizados\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\keras\\src\\losses\\loss.py:107\u001b[0m, in \u001b[0;36msqueeze_or_expand_to_same_rank\u001b[1;34m(x1, x2, expand_rank_1)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msqueeze_or_expand_to_same_rank\u001b[39m(x1, x2, expand_rank_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    106\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Squeeze/expand last dim if ranks differ from expected by exactly 1.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m     x1_rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x1\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    108\u001b[0m     x2_rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x2\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x1_rank \u001b[38;5;241m==\u001b[39m x2_rank:\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot take the length of shape with unknown rank."
     ]
    }
   ],
   "source": [
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
    "\n",
    "# Ajustando o modelo com os dados normalizados\n",
    "history = model.fit(X_train_scaled, y_train_scaled, epochs=1, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 6 features, but StandardScaler is expecting 3705267 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m Y_test_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(y_test)\n\u001b[0;32m      4\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test_scaled, Y_test_scaled)\n",
      "File \u001b[1;32md:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "File \u001b[1;32md:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1045\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1042\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1044\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1045\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32md:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32md:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 6 features, but StandardScaler is expecting 3705267 features as input."
     ]
    }
   ],
   "source": [
    "# Normalizando X_test\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "# Normalizando y_test para a avaliação\n",
    "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Avaliando o desempenho do modelo no conjunto de teste\n",
    "loss = model.evaluate(X_test_scaled, y_test_scaled)\n",
    "print(f'Loss no conjunto de teste: {loss}')\n",
    "\n",
    "# Fazendo previsões\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Desnormalizando as previsões\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
