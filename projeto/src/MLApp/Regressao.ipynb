{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Primeiros dados</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dataframes = pd.DataFrame()\n",
    "\n",
    "base1 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_4a10_spot_3.5a12.2\\\\base_de_dados_1.csv\")\n",
    "results1 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_4a10_spot_3.5a12.2\\\\result_1.csv\")\n",
    "        \n",
    "# df_result_filtrado = results1[(results1['Result'].notna()) & (results1['Result'] != -1)]\n",
    "# indices_to_keep = df_result_filtrado.index\n",
    "# df_inputs_filtrado = base1.loc[indices_to_keep]\n",
    "# df_inputs_filtrado['Result'] = df_result_filtrado['Result']\n",
    "\n",
    "# dataframes = pd.concat([dataframes, df_inputs_filtrado], axis = 0)\n",
    "\n",
    "df_base1 = base1\n",
    "df_base1['Result'] = results1['Result']\n",
    "dataframes = pd.concat([dataframes, df_base1], axis = 0)\n",
    "\n",
    "base2 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_10a15_spot_8.5a17.2\\\\base_de_dados_2.csv\")\n",
    "results2 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_10a15_spot_8.5a17.2\\\\result_2.csv\")\n",
    "\n",
    "df_base2 = base2\n",
    "df_base2['Result'] = results2['Result']\n",
    "dataframes = pd.concat([dataframes, df_base2], axis = 0)\n",
    "\n",
    "base3 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_15a20_spot_12.5a22.5\\\\base_de_dados_3.csv\")\n",
    "results3 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\strike_15a20_spot_12.5a22.5\\\\result_3.csv\")\n",
    "\n",
    "df_base3 = base3\n",
    "df_base3['Result'] = results3['Result']\n",
    "dataframes = pd.concat([dataframes, df_base3], axis = 0)\n",
    "\n",
    "dataframes['CallPut'] = dataframes['CallPut'].replace({'call': 0, 'put': 1})\n",
    "\n",
    "dataframes_testes = dataframes.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Estudo dados - Remoção de outliers</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vol impl do df_estudo inferiores a 0 - 0\n",
      "vol impl inferiores a 5 - 5668080\n",
      "vol impl superior a 5 - 19388\n",
      "vol impl superior a 10 - 6474\n",
      "vol impl superior a 20 - 5235\n",
      "vol impl superior a 50 - 4783\n",
      "vol impl superior a 100 - 4478\n",
      "limite dos outliers - -0.4593854220579583\n",
      "limite dos outliers - 2.211926090524117\n",
      "vol impl inferiores a lowerBound - 0\n",
      "vol impl superior a upperBound - 195852\n",
      "-----\n",
      "limite dos outliers_2 - -2.0017418172182784\n",
      "limite dos outliers_2 - 2.006056214184988\n",
      "vol impl inferiores a lowerBound_2 - 0\n",
      "vol impl superior a upperBound_2 - 260700\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# df_estudo = dataframes[dataframes['Result'] <= 10]\n",
    "\n",
    "df_estudo = dataframes[(dataframes['Result'].notna()) & (dataframes['Result'] != -1) & (dataframes['Result'] > 0)]\n",
    "\n",
    "print(\"vol impl do df_estudo inferiores a 0 - \" + (str)(((df_estudo[df_estudo['Result'] <= 0])).shape[0]))\n",
    "print(\"vol impl inferiores a 5 - \" + (str)(((dataframes[dataframes['Result'] <= 5])).shape[0]))\n",
    "\n",
    "print(\"vol impl superior a 5 - \" + (str)(((dataframes[dataframes['Result'] >= 5])).shape[0]))     \n",
    "print(\"vol impl superior a 10 - \" + (str)(((dataframes[dataframes['Result'] >= 10])).shape[0]))\n",
    "print(\"vol impl superior a 20 - \" + (str)(((dataframes[dataframes['Result'] >= 20])).shape[0]))\n",
    "print(\"vol impl superior a 50 - \" + (str)(((dataframes[dataframes['Result'] >= 50])).shape[0]))\n",
    "print(\"vol impl superior a 100 - \" + (str)(((dataframes[dataframes['Result'] >= 100])).shape[0]))\n",
    "\n",
    "# Calcular os quartis e o IQR\n",
    "Q1 = df_estudo['Result'].quantile(0.25)\n",
    "Q3 = df_estudo['Result'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Determinar os limites inferior e superior para outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(\"limite dos outliers - \" + (str)(lower_bound))\n",
    "print(\"limite dos outliers - \" + (str)(upper_bound))\n",
    "\n",
    "# df_filtrado = dataframes[dataframes['TaxaDesconto']]\n",
    "\n",
    "print(\"vol impl inferiores a lowerBound - \" + (str)(((df_estudo[df_estudo['Result'] <= lower_bound])).shape[0]))\n",
    "\n",
    "print(\"vol impl superior a upperBound - \" + (str)(((df_estudo[df_estudo['Result'] >= upper_bound])).shape[0]))  \n",
    "print(\"-----\")\n",
    "\n",
    "df_novo_sem_outliers = dataframes[dataframes['Result'] < upper_bound]\n",
    "\n",
    "# Q1_2 = df_sem_outliers_1['Result'].quantile(0.25)\n",
    "# Q3_2 = df_sem_outliers_1['Result'].quantile(0.75)\n",
    "# IQR_2 = Q3 - Q1\n",
    "\n",
    "# # Determinar os limites inferior e superior para outliers\n",
    "# lower_bound_2 = Q1_2 - 1.5 * IQR_2b        bb \n",
    "# upper_bound_2 = Q3_2 + 1.5 * IQR_2\n",
    "\n",
    "\n",
    "# print(\"limite dos outliers_2 - \" + (str)(lower_bound_2))\n",
    "# print(\"limite dos outliers_2 - \" + (str)(upper_bound_2))\n",
    "\n",
    "# print(\"vol impl inferiores a lowerBound_2 - \" + (str)(((df_estudo[df_estudo['Result'] <= lower_bound_2])).shape[0]))\n",
    "\n",
    "# print(\"vol impl superior a upperBound_2 - \" + (str)(((df_estudo[df_estudo['Result'] >= upper_bound_2])).shape[0]))  \n",
    "# print(\"-----\")\n",
    "\n",
    "# dataframe_sem_outliers = dataframes[(dataframes['Result'].notna()) & (dataframes['Result'] != -1) & (dataframes['Result'] > 0) & (dataframes['Result'] < upper_bound_2)]\n",
    "\n",
    "\n",
    "# # Identificar os outliers\n",
    "# outliers = df_estudo[(df_estudo['Result'] < lower_bound) | (df_estudo['Result'] > upper_bound)]\n",
    "\n",
    "# # Valor máximo determinado como outlier\n",
    "# max_outlier = outliers['Result'].max()\n",
    "\n",
    "# # Plotar boxplot para visualização dos outliers\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.boxplot(df_estudo['Result'], vert=False)\n",
    "# plt.title('Boxplot dos valores de Result com Outliers')\n",
    "# plt.xlabel('Valores de Result')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # Plotar os outliers em um scatter plot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(outliers.index, outliers['Result'], color='r', label='Outliers')\n",
    "# plt.plot(df_estudo.index, df_estudo['Result'], linestyle='-', alpha=0.5, label='Valores de Result')\n",
    "# plt.title('Outliers identificados no campo Result')\n",
    "# plt.xlabel('Índice')\n",
    "# plt.ylabel('Valores de Result')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # Valor máximo determinado como outlier\n",
    "# max_outlier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Novos dados - redução nos valores do premios</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_9296\\126048534.py:34: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataframes['CallPut'] = dataframes['CallPut'].replace({'call': 0, 'put': 1})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dataframes = pd.DataFrame()\n",
    "\n",
    "base1 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\novos_premios\\\\strike_5a10\\\\strike_5a10.csv\")\n",
    "results1 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\novos_premios\\\\strike_5a10\\\\result.csv\")\n",
    "\n",
    "df_base1 = base1\n",
    "df_base1['Result'] = results1['Result']\n",
    "dataframes = pd.concat([dataframes, df_base1], axis = 0)\n",
    "\n",
    "base2 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\novos_premios\\\\strike_10a15\\\\strike_10a15.csv\")\n",
    "results2 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\novos_premios\\\\strike_10a15\\\\result.csv\")\n",
    "\n",
    "df_base2 = base2\n",
    "df_base2['Result'] = results2['Result']\n",
    "dataframes = pd.concat([dataframes, df_base2], axis = 0)\n",
    "\n",
    "base3 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\novos_premios\\\\strike_15a20\\\\strike_15a20.csv\")\n",
    "results3 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\novos_premios\\\\strike_15a20\\\\result.csv\")\n",
    "\n",
    "df_base3 = base3\n",
    "df_base3['Result'] = results3['Result']\n",
    "dataframes = pd.concat([dataframes, df_base3], axis = 0)\n",
    "\n",
    "base4 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\novos_premios\\\\strike_20a25\\\\strike_20a25.csv\")\n",
    "results4 = pd.read_csv(\"D:\\\\CEDERJ\\\\2024.2\\\\tcc\\\\IVOptionPredictor\\\\projeto\\\\data\\\\iniciais\\\\novos_premios\\\\strike_20a25\\\\result.csv\")\n",
    "\n",
    "df_base4 = base4\n",
    "df_base4['Result'] = results4['Result']\n",
    "dataframes = pd.concat([dataframes, df_base4], axis = 0)\n",
    "\n",
    "dataframes['CallPut'] = dataframes['CallPut'].replace({'call': 0, 'put': 1})\n",
    "\n",
    "dataframes_novos_dados = dataframes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4195200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes_novos_dados.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1670381"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valido = dataframes_novos_dados[(dataframes_novos_dados['Result'].notna()) & (dataframes_novos_dados['Result'] != -1) & (dataframes_novos_dados['Result'] > 0)]\n",
    "\n",
    "df_valido.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Estudo dos dados - novos premios - remoção de outliers</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4195200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes_novos_dados.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_estudo_boxplot = dataframes_novos_dados[(dataframes_novos_dados['Result'].notna()) & (dataframes_novos_dados['Result'] != -1) & (dataframes_novos_dados['Result'] > 0)]\n",
    "\n",
    "# Plotando o boxplot da coluna 'Result'\n",
    "plt.figure(figsize=(4, 6))\n",
    "plt.boxplot(df_estudo_boxplot['Result'])\n",
    "plt.title('Boxplot de Valores de Vol. Implícita')\n",
    "plt.ylabel('Volatilida Implícita')\n",
    "plt.xlabel('')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Exibindo o gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vol impl do df_estudo inferiores a 0 - 0\n",
      "vol impl inferiores a 5 - 4195200\n",
      "vol impl superior a 5 - 0\n",
      "vol impl superior a 10 - 0\n",
      "vol impl superior a 20 - 0\n",
      "vol impl superior a 50 - 0\n",
      "vol impl superior a 100 - 0\n",
      "limite dos outliers - -0.1879640679186795\n",
      "limite dos outliers - 0.9170105345115741\n",
      "vol impl inferiores a lowerBound - 0\n",
      "vol impl superior a upperBound - 35833\n",
      "-----\n",
      "quantidade final - 4159367\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# df_estudo = dataframes_novos_dados[dataframes_novos_dados['Result'] <= 10]\n",
    "\n",
    "df_estudo = dataframes_novos_dados[(dataframes_novos_dados['Result'].notna()) & (dataframes_novos_dados['Result'] != -1) & (dataframes_novos_dados['Result'] > 0)]\n",
    "\n",
    "print(\"vol impl do df_estudo inferiores a 0 - \" + (str)(((df_estudo[df_estudo['Result'] <= 0])).shape[0]))\n",
    "print(\"vol impl inferiores a 5 - \" + (str)(((dataframes_novos_dados[dataframes_novos_dados['Result'] <= 5])).shape[0]))\n",
    "\n",
    "print(\"vol impl superior a 5 - \" + (str)(((dataframes_novos_dados[dataframes_novos_dados['Result'] >= 5])).shape[0]))     \n",
    "print(\"vol impl superior a 10 - \" + (str)(((dataframes_novos_dados[dataframes_novos_dados['Result'] >= 10])).shape[0]))\n",
    "print(\"vol impl superior a 20 - \" + (str)(((dataframes_novos_dados[dataframes_novos_dados['Result'] >= 20])).shape[0]))\n",
    "print(\"vol impl superior a 50 - \" + (str)(((dataframes_novos_dados[dataframes_novos_dados['Result'] >= 50])).shape[0]))\n",
    "print(\"vol impl superior a 100 - \" + (str)(((dataframes_novos_dados[dataframes_novos_dados['Result'] >= 100])).shape[0]))\n",
    "\n",
    "# Calcular os quartis e o IQR\n",
    "Q1 = df_estudo['Result'].quantile(0.25)\n",
    "Q3 = df_estudo['Result'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Determinar os limites inferior e superior para outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(\"limite dos outliers - \" + (str)(lower_bound))\n",
    "print(\"limite dos outliers - \" + (str)(upper_bound))\n",
    "\n",
    "# df_filtrado = dataframes_novos_dados[dataframes_novos_dados['TaxaDesconto']]\n",
    "\n",
    "print(\"vol impl inferiores a lowerBound - \" + (str)(((df_estudo[df_estudo['Result'] <= lower_bound])).shape[0]))\n",
    "\n",
    "print(\"vol impl superior a upperBound - \" + (str)(((df_estudo[df_estudo['Result'] >= upper_bound])).shape[0]))  \n",
    "print(\"-----\")\n",
    "\n",
    "df_novo_sem_outliers_1 = dataframes_novos_dados[dataframes_novos_dados['Result'] < upper_bound]\n",
    "\n",
    "print(\"quantidade final - \" + str(df_novo_sem_outliers_1.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Filtrando dataframe para execução do grid search</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4195200\n",
      "1670381\n",
      "2796800\n",
      "2097600\n",
      "345000\n"
     ]
    }
   ],
   "source": [
    "print(dataframes_novos_dados.shape[0])\n",
    "\n",
    "df_filtrado = dataframes_novos_dados[(dataframes_novos_dados['Result'].notna()) & (dataframes_novos_dados['Result'] != -1) & (dataframes_novos_dados['Result'] > 0)]\n",
    "print(df_filtrado.shape[0])\n",
    "df_filtrado = dataframes_novos_dados[dataframes_novos_dados['TaxaDesconto'].isin([0.08, 0.09, 0.1])]\n",
    "print(df_filtrado.shape[0])\n",
    "df_filtrado = df_filtrado[df_filtrado['Maturity'].isin([0.2, 0.3, 0.4])]\n",
    "print(df_filtrado.shape[0])\n",
    "# df_filtrado = df_filtrado[df_filtrado['CallPut'].isin([0])]\n",
    "# print(df_filtrado.shape[0])\n",
    "\n",
    "df_filtrado = df_filtrado[(df_filtrado['Spot'] >= 9.5) & (df_filtrado['Spot'] <= 13)]\n",
    "# print(df_filtrado.shape[0])\n",
    "\n",
    "dataframe_sem_outliers_filtrado = df_filtrado\n",
    "print(dataframe_sem_outliers_filtrado.shape[0])\n",
    "dataframe_gridSearch = dataframe_sem_outliers_filtrado.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Unnamed: 0  Strike  Maturity  Spot  TaxaDesconto  Premio  CallPut  \\\n",
      "1038082     1038082    19.5       0.4  17.5          0.10    0.05        0   \n",
      "901940       901940    23.4       0.4  17.5          0.11    0.50        0   \n",
      "559485       559485    12.8       0.4  15.8          0.09    0.85        1   \n",
      "781133       781133    14.0       0.2  14.8          0.10    0.20        1   \n",
      "637819       637819    17.8       0.1  20.0          0.11    0.75        1   \n",
      "\n",
      "           Result  \n",
      "1038082  0.086329  \n",
      "901940   0.420400  \n",
      "559485   0.612187  \n",
      "781133   0.231413  \n",
      "637819   0.712271  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_filtrado = dataframes_novos_dados[(dataframes_novos_dados['Result'].notna()) & (dataframes_novos_dados['Result'] != -1) & (dataframes_novos_dados['Result'] > 0)]\n",
    "\n",
    "# Selecionando 400000 registros aleatórios do dataframe existente\n",
    "dataframe_para_gridsearch = df_filtrado.sample(n=400000, random_state=42)\n",
    "\n",
    "# Verificando o novo dataframe\n",
    "print(dataframe_para_gridsearch.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Execução do grid search</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "50 fits failed out of a total of 576.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 489, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 192, in _parallel_build_trees\n",
      "    tree._fit(\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 472, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "  File \"_tree.pyx\", line 172, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 287, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 942, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"_tree.pyx\", line 910, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"_utils.pyx\", line 35, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 16777216 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 489, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 192, in _parallel_build_trees\n",
      "    tree._fit(\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 472, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "  File \"_tree.pyx\", line 172, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 287, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 942, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"_tree.pyx\", line 910, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"_utils.pyx\", line 35, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 8388608 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 489, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 192, in _parallel_build_trees\n",
      "    tree._fit(\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 472, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "  File \"_tree.pyx\", line 172, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 287, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 942, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"_tree.pyx\", line 910, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"_utils.pyx\", line 35, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 4194304 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 489, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 192, in _parallel_build_trees\n",
      "    tree._fit(\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 472, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "  File \"_tree.pyx\", line 172, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 287, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 942, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"_tree.pyx\", line 910, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"_utils.pyx\", line 35, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 2097152 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 489, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 200, in _parallel_build_trees\n",
      "    tree._fit(\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 472, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "  File \"_tree.pyx\", line 172, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 287, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 942, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"_tree.pyx\", line 910, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"_utils.pyx\", line 35, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 16777216 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 489, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 200, in _parallel_build_trees\n",
      "    tree._fit(\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 472, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "  File \"_tree.pyx\", line 172, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 287, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 942, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"_tree.pyx\", line 910, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"_utils.pyx\", line 35, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 33554432 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "11 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 489, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 200, in _parallel_build_trees\n",
      "    tree._fit(\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 472, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "  File \"_tree.pyx\", line 172, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 287, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 942, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"_tree.pyx\", line 910, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"_utils.pyx\", line 35, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 8388608 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 489, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 200, in _parallel_build_trees\n",
      "    tree._fit(\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 472, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "  File \"_tree.pyx\", line 172, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 287, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 942, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"_tree.pyx\", line 910, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"_utils.pyx\", line 35, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 2097152 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 489, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 200, in _parallel_build_trees\n",
      "    tree._fit(\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 472, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "  File \"_tree.pyx\", line 172, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 287, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 942, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"_tree.pyx\", line 910, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"_utils.pyx\", line 35, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 4194304 bytes\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [-0.01712071 -0.01707334         nan         nan -0.01500793 -0.01498838\n",
      " -0.0149809  -0.01497323 -0.01583949 -0.0158049  -0.01579006 -0.01578773\n",
      " -0.01507158 -0.01504739 -0.0150286  -0.01503049 -0.01978563 -0.01978253\n",
      "         nan         nan         nan -0.01644727 -0.01642276 -0.01640528\n",
      " -0.01734261 -0.01730751 -0.01730865 -0.01728695 -0.01619915 -0.01619556\n",
      " -0.01618739 -0.01619699 -0.01981107 -0.01982925         nan         nan\n",
      " -0.0164547  -0.01643699 -0.01642395 -0.01640672 -0.01733319 -0.01730127\n",
      " -0.01730255 -0.01729408 -0.01622399 -0.01620023 -0.01617517 -0.01617557\n",
      " -0.01569991 -0.01568064 -0.01567652 -0.01567336 -0.01566509 -0.01566826\n",
      " -0.01566305 -0.01566475 -0.01569333 -0.01568626 -0.01568111 -0.01568079\n",
      " -0.01567315 -0.01567771 -0.01567856 -0.0156709  -0.01523809 -0.0152179\n",
      " -0.01521766 -0.01520688 -0.01521468 -0.01521967 -0.01520808 -0.01522666\n",
      " -0.01523672 -0.01521906 -0.01523866 -0.01523724 -0.01523039 -0.01524687\n",
      " -0.01521604 -0.01521764 -0.01523128 -0.01522921 -0.01522612 -0.01521707\n",
      " -0.01522876 -0.0152217  -0.01522285 -0.01520808 -0.01526458 -0.01522553\n",
      " -0.01522422 -0.0152328  -0.01523269 -0.01521719 -0.0152252  -0.01521736\n",
      " -0.02543458         nan         nan         nan         nan -0.01947032\n",
      " -0.01947027 -0.01947028 -0.02117761 -0.02117775 -0.0211779  -0.02117791\n",
      " -0.018834   -0.01883398 -0.01883398         nan -0.02535473         nan\n",
      "         nan         nan -0.01892675         nan -0.01889113 -0.0188755\n",
      " -0.02041896 -0.02044792 -0.02041128 -0.02038834 -0.01815861 -0.01821107\n",
      " -0.01821463 -0.0182126  -0.02539857         nan         nan         nan\n",
      " -0.01893            nan         nan -0.01888352 -0.02045177 -0.02041865\n",
      " -0.02039566         nan -0.01819839         nan -0.01818068 -0.01820712\n",
      " -0.01635045 -0.0163503  -0.01635041 -0.01635028 -0.01630725 -0.01630725\n",
      " -0.01630725 -0.01630725 -0.01634735 -0.01634735 -0.01634735 -0.01634735\n",
      " -0.01631674 -0.01631674 -0.01631674 -0.01631674 -0.01524831 -0.01523935\n",
      " -0.01523284 -0.01524127 -0.01523607 -0.01523202 -0.01524564 -0.01524582\n",
      " -0.0152677  -0.0152507  -0.01524686 -0.01523952 -0.01528376 -0.0152341\n",
      " -0.01525614 -0.01524071 -0.01526499 -0.01524721 -0.01523847 -0.01524812\n",
      " -0.01525463 -0.01527189 -0.01524342 -0.01523949 -0.01526522 -0.01524544\n",
      " -0.01525774 -0.01523092 -0.01526659 -0.01523923 -0.01523715 -0.01524359]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor modelo e hiperparâmetros: {'model': RandomForestRegressor(), 'model__bootstrap': True, 'model__max_depth': None, 'model__max_features': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 400}\n",
      "MSE no conjunto de teste: 0.014414265365131924\n",
      "R² no conjunto de teste: 0.689901681901238\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "dataframe_gridSearch_limpo = dataframe_para_gridsearch[(dataframe_para_gridsearch['Result'].notna()) & (dataframe_para_gridsearch['Result'] != -1)]\n",
    "\n",
    "# Dados de entrada e variável alvo\n",
    "dataframe_gridSearch_limpo['Spot/Strike'] = dataframe_gridSearch_limpo['Spot']/dataframe_gridSearch_limpo['Strike']\n",
    "\n",
    "X = dataframe_gridSearch_limpo[['Spot/Strike', 'Maturity', 'TaxaDesconto', 'Premio', 'CallPut']].values\n",
    "y = dataframe_gridSearch_limpo['Result'].values\n",
    "\n",
    "# Divisão treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Definir o pipeline\n",
    "pipeline = Pipeline([ # Normalizar os dados\n",
    "    ('model', LinearRegression())  # Placeholder para o modelo, será substituído\n",
    "])\n",
    "\n",
    "# Dicionário com modelos e seus hiperparâmetros\n",
    "param_grid = [\n",
    "    {\n",
    "        'model': [RandomForestRegressor()],\n",
    "        'model__n_estimators': [100, 200, 300, 400],\n",
    "        'model__max_depth': [None, 10],\n",
    "        'model__min_samples_split': [2, 10],\n",
    "        'model__min_samples_leaf': [1, 2],\n",
    "        'model__max_features': [None, 'sqrt', 'log2'],\n",
    "        'model__bootstrap': [True, False]\n",
    "    }\n",
    "]\n",
    "\n",
    "# GridSearchCV para encontrar o melhor modelo e hiperparâmetros\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Ajuste do GridSearch com os dados de treino\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Melhor modelo encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Melhor modelo e hiperparâmetros:\", grid_search.best_params_)\n",
    "\n",
    "# Avaliação no conjunto de teste\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE no conjunto de teste: {mse}\")\n",
    "print(f\"R² no conjunto de teste: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Treinamento do modelo random forest</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LIMPEZA DOS DADOS\n",
    "dataframes_RF = dataframes_novos_dados.copy()\n",
    "\n",
    "df_result_filtrado = dataframes_RF[(dataframes_RF['Result'].notna()) & (dataframes_RF['Result'] != -1)]\n",
    "# indices_to_keep = df_result_filtrado.index\n",
    "# df_inputs_filtrado = base3.loc[indices_to_keep]\n",
    "# df_inputs_filtrado['Result'] = df_result_filtrado['Result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>montagem dataset treino</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_32344\\1972460305.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_result_filtrado['Str/Spot'] = df_result_filtrado['Strike']/df_result_filtrado['Spot']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1670391\n"
     ]
    }
   ],
   "source": [
    "df_result_filtrado['Str/Spot'] = df_result_filtrado['Strike']/df_result_filtrado['Spot']\n",
    "\n",
    "X = df_result_filtrado[['Str/Spot', 'Maturity', 'TaxaDesconto', 'Premio', 'CallPut']].values\n",
    "y = df_result_filtrado['Result'].values\n",
    "print(df_result_filtrado.shape[0])\n",
    "X_train_RF, X_test_RF, y_train_RF, y_test_RF = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# scaler_X_RF = StandardScaler()\n",
    "# scaler_y_RF = StandardScaler()\n",
    "# model_RF = RandomForestRegressor()\n",
    "\n",
    "# Ajustar e transformar os dados de treino\n",
    "# X_train_scaled_RF = scaler_X_RF.fit_transform(X_train_RF)\n",
    "# y_train_scaled_RF = scaler_y_RF.fit_transform(y_train_RF.reshape(-1, 1))\n",
    "\n",
    "# X_test_scaled_RF = scaler_X_RF.fit_transform(X_test_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE no conjunto de teste: 0.02120402556375423\n",
      "R² no conjunto de teste: 0.5460479999578838\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='sqrt',\n",
    "    min_samples_split=2, \n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Definir o KFold para a validação cruzada\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Usar cross_val_score para calcular o MSE e R² em cada dobra\n",
    "# mse_scorer_RF = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "# r2_scorer_RF = make_scorer(r2_score)\n",
    "\n",
    "# mse_scores_RF = cross_val_score(rf_model, X_train_scaled_RF, y_train_scaled_RF, cv=kf, scoring=mse_scorer_RF)\n",
    "# r2_scores_RF = cross_val_score(rf_model, X_train_scaled_RF, y_train_scaled_RF, cv=kf, scoring=r2_scorer_RF)\n",
    "\n",
    "# Ajustar o modelo aos dados de treino\n",
    "rf_model.fit(X_train_RF, y_train_RF)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred_RF = rf_model.predict(X_test_RF)\n",
    "# y_pred_RF = scaler_y_RF.inverse_transform(y_pred_RF_scaled.reshape(-1, 1))\n",
    "\n",
    "# Avaliar o modelo no conjunto de teste\n",
    "mse_test_RF = mean_squared_error(y_test_RF, y_pred_RF)\n",
    "r2_test_RF = r2_score(y_test_RF, y_pred_RF)\n",
    "\n",
    "# Resultados da validação cruzada e do conjunto de teste\n",
    "# print(f\"MSE médio (validação cruzada): {-np.mean(mse_scores_RF)}\")\n",
    "# print(f\"R² médio (validação cruzada): {np.mean(r2_scores_RF)}\")\n",
    "print(f\"MSE no conjunto de teste: {mse_test_RF}\")\n",
    "print(f\"R² no conjunto de teste: {r2_test_RF}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_treinado.joblib']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### salvando o modelo\n",
    "#################### pip install joblib\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "# Supondo que 'best_model' seja o modelo treinado (por exemplo, após o GridSearchCV)\n",
    "dump(rf_model, 'random_forest_treinado_ajuste_strike_sobrs_spot.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## carregando modelo\n",
    "\n",
    "from joblib import load\n",
    "\n",
    "# Carregar o modelo salvo\n",
    "modelo_carregado = load('random_forest_treinado_ajuste_strike_sobrs_spot.joblib')\n",
    "\n",
    "# Usar o modelo carregado para fazer previsões\n",
    "####### predicoes = modelo_carregado.predict(X_novo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Estudo do modelo Random Rorest Regressor</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5986511811528638\n",
      "0.312423343874996\n",
      "0.37206446401414617\n",
      "0.42599978724162596\n",
      "0.46472081199409454\n",
      "0.5098586378848359\n",
      "0.5540094057068596\n",
      "------\n",
      "        Unnamed: 0  Strike  Maturity  Spot  TaxaDesconto  Premio  CallPut  \\\n",
      "664069      664069     9.1       0.2  11.0          0.09    0.35        1   \n",
      "680065      680065     9.2       0.2  11.0          0.09    0.05        1   \n",
      "680067      680067     9.2       0.2  11.0          0.09    0.10        1   \n",
      "680069      680069     9.2       0.2  11.0          0.09    0.15        1   \n",
      "680071      680071     9.2       0.2  11.0          0.09    0.20        1   \n",
      "680073      680073     9.2       0.2  11.0          0.09    0.25        1   \n",
      "680075      680075     9.2       0.2  11.0          0.09    0.30        1   \n",
      "\n",
      "          Result  \n",
      "664069  0.612911  \n",
      "680065  0.312259  \n",
      "680067  0.376254  \n",
      "680069  0.427672  \n",
      "680071  0.473206  \n",
      "680073  0.515246  \n",
      "680075  0.554952  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "df_RF_estudo = dataframes_novos_dados.copy()\n",
    "\n",
    "df_result_filtrado_RF = df_RF_estudo[(df_RF_estudo['Result'].notna()) & (df_RF_estudo['Result'] != -1)]\n",
    "\n",
    "df_estudo_vencimento = df_result_filtrado_RF[(df_result_filtrado_RF['Maturity'] == 0.2) & (df_result_filtrado_RF['TaxaDesconto'] == 0.09) & (df_result_filtrado_RF['Spot'] == 11)]\n",
    "# print(df_estudo_vencimento)\n",
    "dados_x_RF = df_estudo_vencimento[['Strike', 'Maturity', 'Spot', 'TaxaDesconto', 'Premio', 'CallPut']].values\n",
    "# print(df_estudo_vencimento[['Result']].values[10:15])\n",
    "# dados_x_RF_scaled = scaler_X_RF.fit_transform(dados_x_RF)\n",
    "\n",
    "y_pred_estudo_RF = rf_model.predict(dados_x_RF)\n",
    "\n",
    "# y_estudo_reescalado = scaler_y_RF.inverse_transform(y_pred_estudo_RF.reshape(-1, 1))\n",
    "\n",
    "print(y_pred_estudo_RF[20])\n",
    "print(y_pred_estudo_RF[21])\n",
    "print(y_pred_estudo_RF[22])\n",
    "print(y_pred_estudo_RF[23])\n",
    "print(y_pred_estudo_RF[24])\n",
    "print(y_pred_estudo_RF[25])\n",
    "print(y_pred_estudo_RF[26])\n",
    "\n",
    "print(\"------\")\n",
    "\n",
    "print(df_estudo_vencimento[20:27])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_estudo_reescalado)\n",
    "df.to_csv(\"resultados.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>grid search do modelo sgboost</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "180 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1108, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.2 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1108, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.4 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [-0.00019237 -0.0001857  -0.00018203 -0.00019216 -0.00018469 -0.00018208\n",
      " -0.00018254 -0.00017756 -0.00017521 -0.00018141 -0.000176   -0.00017476\n",
      " -0.00017507 -0.00017185 -0.00017057 -0.0001739  -0.00016983 -0.00016961\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor modelo e hiperparâmetros: {'model__colsample_bytree': 1.0, 'model__gamma': 0, 'model__learning_rate': 0.1, 'model__max_depth': 15, 'model__n_estimators': 400, 'model__reg_alpha': 0, 'model__reg_lambda': 3.5, 'model__subsample': 0.5}\n",
      "MSE no conjunto de teste: 0.00013718509614269863\n",
      "R² no conjunto de teste: 0.9970486967941513\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Dados de entrada e variável alvo\n",
    "X = dataframe_para_gridsearch[['Strike', 'Maturity', 'Spot', 'TaxaDesconto', 'Premio', 'CallPut']].values\n",
    "y = dataframe_para_gridsearch['Result'].values\n",
    "\n",
    "# Divisão treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Definir o pipeline\n",
    "pipeline2 = Pipeline([  \n",
    "    ('model', XGBRegressor())  # Substituir o modelo pelo XGBRegressor\n",
    "])\n",
    "\n",
    "# Dicionário com hiperparâmetros para o XGBoost\n",
    "param_grid2 = {\n",
    "    # 'model__n_estimators': [50, 100],\n",
    "    # 'model__max_depth': [None, 10, 5],\n",
    "    # 'model__learning_rate': [0.01, 0.1],\n",
    "    # 'model__subsample': [0.8, 1.0]\n",
    "    # 'model__n_estimators': [100, 150, 200],\n",
    "    # 'model__max_depth': [10, 15],\n",
    "    # 'model__learning_rate': [0.1, 0.15],\n",
    "    # 'model__subsample': [0.7, 0.8],\n",
    "    # 'model__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    # 'model__gamma': [0, 0.1, 0.2],\n",
    "    # 'model__reg_alpha': [0, 0.1, 0.5],\n",
    "    # 'model__reg_lambda': [1, 1.5, 2],\n",
    "    'model__n_estimators': [300, 350, 400],\n",
    "    'model__max_depth': [15],\n",
    "    'model__learning_rate': [0.1],\n",
    "    'model__subsample': [0.3, 0.4, 0.5],\n",
    "    'model__colsample_bytree': [1.0, 1.2, 1.4],\n",
    "    'model__gamma': [0],\n",
    "    'model__reg_alpha': [0],\n",
    "    'model__reg_lambda': [3, 3.5]\n",
    "}\n",
    "\n",
    "# GridSearchCV para encontrar o melhor modelo e hiperparâmetros\n",
    "grid_search2 = GridSearchCV(pipeline2, param_grid2, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Ajuste do GridSearch com os dados de treino\n",
    "grid_search2.fit(X_train, y_train)\n",
    "\n",
    "# Melhor modelo encontrado\n",
    "best_model2 = grid_search2.best_estimator_\n",
    "\n",
    "print(\"Melhor modelo e hiperparâmetros:\", grid_search2.best_params_)\n",
    "\n",
    "# Avaliação no conjunto de teste\n",
    "y_pred = best_model2.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE no conjunto de teste: {mse}\")\n",
    "print(f\"R² no conjunto de teste: {r2}\")\n",
    "\n",
    "# Exemplo de previsão com o melhor modelo\n",
    "# new_data = np.array([[strike, maturity, spot, taxa_desconto, premio, callput]])\n",
    "# predicted_vol = best_model.predict(new_data)\n",
    "# print(f\"Volatilidade implícita estimada: {predicted_vol}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Treinamento do sgboost</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE no conjunto de teste: 3.365166935563625e-05\n",
      "R² no conjunto de teste: 0.9992795593193936\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "dataframes_boost = dataframes_novos_dados.copy()\n",
    "dataframes_novos_dados\n",
    "df_boost = dataframes_boost[(dataframes_boost['Result'].notna()) & (dataframes_boost['Result'] != -1)]\n",
    "\n",
    "# Dados de entrada e variável alvo\n",
    "X = df_boost[['Strike', 'Maturity', 'Spot', 'TaxaDesconto', 'Premio', 'CallPut']].values\n",
    "y = df_boost['Result'].values\n",
    "\n",
    "# Divisão treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Definir o pipeline com StandardScaler e XGBRegressor\n",
    "pipeline_sgboost = Pipeline([  # Normalizar os dados\n",
    "    ('model', XGBRegressor(\n",
    "        colsample_bytree=1.0,\n",
    "        gamma=0,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=15,\n",
    "        n_estimators=400,\n",
    "        reg_alpha=0,\n",
    "        reg_lambda=3.5,\n",
    "        subsample=0.5\n",
    "    ))  # Utilizando os hiperparâmetros fornecidos\n",
    "])\n",
    "# Melhor modelo e hiperparâmetros: {'model__colsample_bytree': 1.0, 'model__gamma': 0, \n",
    "# 'model__learning_rate': 0.1, 'model__max_depth': 15, 'model__n_estimators': 400,\n",
    "#  'model__reg_alpha': 0, 'model__reg_lambda': 3.5, 'model__subsample': 0.5}\n",
    "\n",
    "# Definir o KFold para a validação cruzada\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# # Usar cross_val_score para calcular o MSE e R² em cada dobra\n",
    "# mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "# r2_scorer = make_scorer(r2_score)\n",
    "\n",
    "# mse_scores = cross_val_score(pipeline_sgboost, X_train, y_train, cv=kf, scoring=mse_scorer)\n",
    "# r2_scores = cross_val_score(pipeline_sgboost, X_train, y_train, cv=kf, scoring=r2_scorer)\n",
    "\n",
    "# Treinar o modelo com os dados de treino\n",
    "pipeline_sgboost.fit(X_train, y_train)\n",
    "\n",
    "# Avaliação do modelo no conjunto de teste\n",
    "y_pred = pipeline_sgboost.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE no conjunto de teste: {mse}\")\n",
    "print(f\"R² no conjunto de teste: {r2}\")\n",
    "\n",
    "# Exemplo de previsão com o melhor modelo\n",
    "# new_data = np.array([[strike, maturity, spot, taxa_desconto, premio, callput]])\n",
    "# predicted_vol = pipeline.predict(new_data)\n",
    "# print(f\"Volatilidade implícita estimada: {predicted_vol}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boost_treinado.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### salvando o modelo\n",
    "#################### pip install joblib\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "# Supondo que 'best_model' seja o modelo treinado (por exemplo, após o GridSearchCV)\n",
    "dump(pipeline_sgboost, 'boost_treinado_ajuste_strike_sobrs_spot.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## carregando modelo\n",
    "\n",
    "from joblib import load\n",
    "\n",
    "# Carregar o modelo salvo\n",
    "modelo_boost_carregado = load('boost_treinado_ajuste_strike_sobrs_spot.joblib')\n",
    "\n",
    "# Usar o modelo carregado para fazer previsões\n",
    "####### predicoes = modelo_carregado.predict(X_novo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Estudo do modelo sgboost</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6110981\n",
      "0.31246638\n",
      "0.37613168\n",
      "0.42771056\n",
      "0.4667393\n",
      "0.5146922\n",
      "0.5569345\n",
      "------\n",
      "        Unnamed: 0  Strike  Maturity  Spot  TaxaDesconto  Premio  CallPut  \\\n",
      "664069      664069     9.1       0.2  11.0          0.09    0.35        1   \n",
      "680065      680065     9.2       0.2  11.0          0.09    0.05        1   \n",
      "680067      680067     9.2       0.2  11.0          0.09    0.10        1   \n",
      "680069      680069     9.2       0.2  11.0          0.09    0.15        1   \n",
      "680071      680071     9.2       0.2  11.0          0.09    0.20        1   \n",
      "680073      680073     9.2       0.2  11.0          0.09    0.25        1   \n",
      "680075      680075     9.2       0.2  11.0          0.09    0.30        1   \n",
      "\n",
      "          Result  \n",
      "664069  0.612911  \n",
      "680065  0.312259  \n",
      "680067  0.376254  \n",
      "680069  0.427672  \n",
      "680071  0.473206  \n",
      "680073  0.515246  \n",
      "680075  0.554952  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "df_estudo_boost = dataframes_novos_dados.copy()\n",
    "\n",
    "df_result_filtrado_boost = df_estudo_boost[(df_estudo_boost['Result'].notna()) & (df_estudo_boost['Result'] != -1)]\n",
    "\n",
    "df_estudo_vencimento = df_result_filtrado_boost[(df_result_filtrado_boost['Maturity'] == 0.2) & (df_result_filtrado_boost['TaxaDesconto'] == 0.09) & (df_result_filtrado_boost['Spot'] == 11)]\n",
    "# print(df_estudo_vencimento)\n",
    "dados_x_boost = df_estudo_vencimento[['Strike', 'Maturity', 'Spot', 'TaxaDesconto', 'Premio', 'CallPut']].values\n",
    "# print(df_estudo_vencimento[['Result']].values[10:15])\n",
    "# dados_x_boost_scaled = scaler_X_boost.fit_transform(dados_x_boost)\n",
    "\n",
    "y_pred_estudo_boost = modelo_boost_carregado.predict(dados_x_boost)\n",
    "\n",
    "# y_estudo_reescalado = scaler_y_boost.inverse_transform(y_pred_estudo_boost.reshape(-1, 1))\n",
    "\n",
    "print(y_pred_estudo_boost[20])\n",
    "print(y_pred_estudo_boost[21])\n",
    "print(y_pred_estudo_boost[22])\n",
    "print(y_pred_estudo_boost[23])\n",
    "print(y_pred_estudo_boost[24])\n",
    "print(y_pred_estudo_boost[25])\n",
    "print(y_pred_estudo_boost[26])\n",
    "\n",
    "print(\"------\")\n",
    "\n",
    "print(df_estudo_vencimento[20:27])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Rede Neural</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Grid search</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor modelo e hiperparâmetros: {'batch_size': 128, 'epochs': 50, 'model__activation': 'relu', 'model__dropout_rate': 0, 'model__hidden_layers': 2, 'model__init': 'uniform', 'model__learning_rate': 0.001, 'model__neurons': 200}\n",
      "MSE no conjunto de teste: 2.5052116257904623e-05\n",
      "R² no conjunto de teste: 0.9994610464758625\n"
     ]
    }
   ],
   "source": [
    "from scikeras.wrappers import KerasRegressor  # Use scikeras para integrar Keras com scikit-learn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "dataframe_gridSearch_limpo = dataframe_para_gridsearch[(dataframe_para_gridsearch['Result'].notna()) & (dataframe_para_gridsearch['Result'] != -1)]\n",
    "X_redeNeural = dataframe_gridSearch_limpo[['Strike', 'Maturity', 'Spot', 'TaxaDesconto', 'Premio', 'CallPut']].values\n",
    "y_redeNeural = dataframe_gridSearch_limpo['Result'].values\n",
    "\n",
    "X_train_redeNeural, X_test_redeNeural, y_train_redeNeural, y_test_redeNeural = train_test_split(X_redeNeural, y_redeNeural, test_size=0.3, random_state=42)\n",
    "\n",
    "# Função para criar o modelo com os hiperparâmetros como entrada\n",
    "def create_model(neurons=100, activation='relu', hidden_layers=1, init='uniform', learning_rate=1e-3, dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=input_dim, kernel_initializer=init, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Adicionar camadas ocultas adicionais, se necessário\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(neurons, kernel_initializer=init, activation=activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Camada de saída (ajustar para seu problema)\n",
    "    model.add(Dense(1, kernel_initializer=init))\n",
    "    \n",
    "    # Compilar o modelo\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "# Definir input_dim com base no seu conjunto de dados\n",
    "input_dim = X_train_redeNeural.shape[1]  # ajuste 'X_train' conforme necessário\n",
    "\n",
    "# Wrapping the Keras model for use with scikit-learn\n",
    "model = KerasRegressor(model=create_model, verbose=0)\n",
    "# Hiperparâmetros para o Grid Search\n",
    "param_grid = {  \n",
    "    # 'model__neurons': [20, 50, 100, 200, 300],\n",
    "    # 'model__neurons': [20, 50, 100],\n",
    "    'model__neurons': [200],\n",
    "    # 'model__activation': ['relu', 'tanh'],\n",
    "    'model__activation': ['tanh','relu'],\n",
    "    # 'model__hidden_layers': [1, 2, 3],\n",
    "    'model__hidden_layers': [2, 5, 4],\n",
    "    # 'model__init': ['uniform', 'he_uniform'],\n",
    "    'model__init': ['uniform'],\n",
    "    # 'model__learning_rate': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    'model__learning_rate': [1e-3],\n",
    "    'model__dropout_rate': [0],\n",
    "    # 'batch_size': [128, 256, 512],\n",
    "    'batch_size': [128],\n",
    "    'epochs':   [50]\n",
    "}\n",
    "\n",
    "# Executar o Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3, verbose=1, n_jobs=4)\n",
    "grid_result = grid.fit(X_train_redeNeural, y_train_redeNeural)\n",
    "\n",
    "best_model3 = grid_result.best_estimator_\n",
    "\n",
    "print(\"Melhor modelo e hiperparâmetros:\", grid_result.best_params_)\n",
    "\n",
    "# Avaliação no conjunto de teste\n",
    "y_pred_redeNeural = best_model3.predict(X_test_redeNeural)\n",
    "mse = mean_squared_error(y_test_redeNeural, y_pred_redeNeural)\n",
    "r2 = r2_score(y_test_redeNeural, y_pred_redeNeural)\n",
    "\n",
    "print(f\"MSE no conjunto de teste: {mse}\")\n",
    "print(f\"R² no conjunto de teste: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Treinamento Rede Neural</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CEDERJ\\2024.2\\tcc\\IVOptionPredictor\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - loss: 0.0069 - val_loss: 1.3521e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 1.4887e-04 - val_loss: 6.4772e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 9.8491e-05 - val_loss: 3.6224e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 7.8578e-05 - val_loss: 5.7128e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 7.1811e-05 - val_loss: 3.1282e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 6.4137e-05 - val_loss: 4.6625e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - loss: 5.6654e-05 - val_loss: 2.8223e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 5.2762e-05 - val_loss: 2.6508e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 5.0083e-05 - val_loss: 4.1157e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 4.6752e-05 - val_loss: 4.1474e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 4.4307e-05 - val_loss: 1.8783e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 4.9027e-05 - val_loss: 3.8503e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 4.4112e-05 - val_loss: 4.3208e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - loss: 4.1609e-05 - val_loss: 1.6345e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 3.9730e-05 - val_loss: 3.7904e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 4.0880e-05 - val_loss: 2.5285e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 3.6891e-05 - val_loss: 4.9630e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 3.6394e-05 - val_loss: 3.0590e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 3.1182e-05 - val_loss: 1.5696e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 3.4915e-05 - val_loss: 1.1569e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 3.1789e-05 - val_loss: 1.4739e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 2.9512e-05 - val_loss: 4.5759e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 2.9253e-05 - val_loss: 1.7450e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 2.8800e-05 - val_loss: 1.3553e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 2.7715e-05 - val_loss: 1.2528e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 3.0353e-05 - val_loss: 4.2833e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 3.2668e-05 - val_loss: 2.6149e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 2.8057e-05 - val_loss: 1.4298e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 2.8759e-05 - val_loss: 1.5308e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - loss: 2.8320e-05 - val_loss: 2.8527e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 3.0253e-05 - val_loss: 1.2111e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 2.8511e-05 - val_loss: 2.5475e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 2.4643e-05 - val_loss: 4.6270e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 2.5806e-05 - val_loss: 1.4159e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 2.3346e-05 - val_loss: 1.4578e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 2.3154e-05 - val_loss: 1.1320e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 2.2826e-05 - val_loss: 2.3643e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 2.3806e-05 - val_loss: 1.8009e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 2.1781e-05 - val_loss: 1.9916e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 2.3476e-05 - val_loss: 3.3423e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 2.1486e-05 - val_loss: 9.6958e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 2.2938e-05 - val_loss: 3.3959e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 2.1766e-05 - val_loss: 1.9188e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - loss: 2.2761e-05 - val_loss: 1.9775e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 2.0969e-05 - val_loss: 1.8717e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - loss: 2.0652e-05 - val_loss: 1.3563e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 2.1836e-05 - val_loss: 1.6569e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 1.9706e-05 - val_loss: 1.1615e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - loss: 2.4902e-05 - val_loss: 1.0777e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m7308/7308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 1.9579e-05 - val_loss: 5.1726e-05\n",
      "\u001b[1m15660/15660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step\n",
      "MSE no conjunto de teste: 5.219957640237853e-05\n",
      "R² no conjunto de teste: 0.9988824715364559\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n",
      "Predição para o novo exemplo: [[1.0725842]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Função para criar o model_redeneuralo com os melhores hiperparâmetros\n",
    "def create_best_model_redeneural():\n",
    "    model_redeneural = Sequential()\n",
    "    \n",
    "    # Primeira camada oculta com 200 neurônios, 'relu' como ativação e 'uniform' como inicializador\n",
    "    model_redeneural.add(Dense(200, input_dim=input_dim, kernel_initializer='uniform', activation='relu'))\n",
    "    model_redeneural.add(Dropout(0))  # Taxa de dropout 0\n",
    "    \n",
    "    # Segunda camada oculta (configurada com 2 camadas ocultas no total)\n",
    "    model_redeneural.add(Dense(200, kernel_initializer='uniform', activation='relu'))\n",
    "    model_redeneural.add(Dropout(0))  # Outra camada Dropout com taxa 0\n",
    "    \n",
    "    # Camada de saída\n",
    "    model_redeneural.add(Dense(1, kernel_initializer='uniform'))\n",
    "    \n",
    "    # Compilar o model_redeneuralo com otimizador Adam e taxa de aprendizado de 0.001\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model_redeneural.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    return model_redeneural\n",
    "\n",
    "# Definir input_dim com base no seu conjunto de dados\n",
    "input_dim = X_train_redeNeural.shape[1]\n",
    "\n",
    "# Criar o model_redeneuralo com os melhores hiperparâmetros\n",
    "model_redeneural = create_best_model_redeneural()\n",
    "\n",
    "dataframes_redeneural = dataframes_novos_dados.copy()\n",
    "df_redeneural = dataframes_redeneural[(dataframes_redeneural['Result'].notna()) & (dataframes_redeneural['Result'] != -1)]\n",
    "\n",
    "# Dados de entrada e variável alvo\n",
    "X_redeneural = df_redeneural[['Strike', 'Maturity', 'Spot', 'TaxaDesconto', 'Premio', 'CallPut']].values\n",
    "y_redeneural = df_redeneural['Result'].values\n",
    "\n",
    "X_train_redeNeural, X_test_redeNeural, y_train_redeNeural, y_test_redeNeural = train_test_split(X_redeneural, y_redeneural, test_size=0.3, random_state=42)\n",
    "\n",
    "# Treinamento do model_redeneuralo\n",
    "history = model_redeneural.fit(X_train_redeNeural, y_train_redeNeural, batch_size=128, epochs=50, verbose=1, validation_split=0.2)\n",
    "\n",
    "# Fazer predições no conjunto de teste\n",
    "y_pred_redeNeural = model_redeneural.predict(X_test_redeNeural)\n",
    "\n",
    "# Avaliação do model_redeneuralo no conjunto de teste\n",
    "mse = mean_squared_error(y_test_redeNeural, y_pred_redeNeural)\n",
    "r2 = r2_score(y_test_redeNeural, y_pred_redeNeural)\n",
    "\n",
    "print(f\"MSE no conjunto de teste: {mse}\")\n",
    "print(f\"R² no conjunto de teste: {r2}\")\n",
    "\n",
    "# Exemplo de predição com novos dados\n",
    "novo_exemplo = np.array([[100, 1, 110, 0.05, 12, 1]])  # Substituir pelos seus dados reais\n",
    "predicao = model_redeneural.predict(novo_exemplo)\n",
    "print(f\"Predição para o novo exemplo: {predicao}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rede_neural.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Supondo que 'best_model' seja o modelo treinado (por exemplo, após o GridSearchCV)\n",
    "dump(model_redeneural, 'rede_neural.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
